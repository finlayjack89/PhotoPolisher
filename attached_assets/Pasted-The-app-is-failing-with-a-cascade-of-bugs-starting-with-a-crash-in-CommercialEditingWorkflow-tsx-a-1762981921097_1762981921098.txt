The app is failing with a cascade of bugs, starting with a crash in CommercialEditingWorkflow.tsx, a failed add-drop-shadow call, and failed AI floor detection.

The root causes are:

State Crash: CommercialEditingWorkflow.tsx has a race condition and crashes because analysisResults is undefined on first render.

API Key Error: remove-backgrounds.ts is still using the wrong REPLICATE_API_TOKEN env variable.

Missing API: The /api/analyze-backdrop endpoint is completely missing from the server and client.

Bad Upload: add-drop-shadow.ts is sending a malformed data URL to Cloudinary, causing a 400 error.

Faulty Loop: BackgroundRemovalStep.tsx is still using the old, server-crashing "send-all-at-once" logic.

We will fix all bugs and implement the final architecture.

Phase 1: Fix Initial Crash & API Key

Fix CommercialEditingWorkflow.tsx Crash:

Open: src/components/CommercialEditingWorkflow.tsx.

Delete: Remove the useEffect hook (lines 33-35) and the entire analyzeImages function (lines 52-68).

Fix State Initialization (Stops Crash):

Change line 22 (workflowFiles) to:

TypeScript

const [workflowFiles, setWorkflowFiles] = useState<FileWithOriginalSize[]>(
  files.map(f => ({ ...f, name: f.name, size: f.size, type: f.type, originalSize: f.size, isPreCut: f.isPreCut }))
);
Change line 24 (analysisResults) to:

TypeScript

const [analysisResults, setAnalysisResults] = useState<AnalysisResult[]>(
  files.map(f => ({
    originalName: f.name,
    originalSize: (f as FileWithOriginalSize).originalSize || f.size,
    compressedSize: f.size,
    compressionRatio: (f as FileWithOriginalSize).originalSize ? `${Math.round(100 - (f.size / (f as FileWithOriginalSize).originalSize!) * 100)}%` : '0%',
    qualityPercentage: 92
  }))
);
Fix handleAnalysisComplete function:

TypeScript

const handleAnalysisComplete = () => {
  const allPreCut = workflowFiles.every(file => file.isPreCut);
  if (allPreCut) {
    setCurrentStep('precut-positioning');
  } else {
    setCurrentStep('background-removal');
  }
};
Fix ImagePreviewStep Props (line 72):

TypeScript

<ImagePreviewStep
  files={workflowFiles}
  onContinue={handleAnalysisComplete} // Pass the correct function
  onBack={onBack}
  wasCompressed={true}
  compressionData={analysisResults} // Pass the state array
/>
Remove Redundant Steps: In the WorkflowStep type (line 15) and the render logic, remove 'rotation' and 'shadow-generation'.

Fix API Key:

In server/image-processing/remove-backgrounds.ts, change all four (4) instances of REPLICATE_API_TOKEN to REPLICATE_API_KEY.

Phase 2: Fix Server-Side API Logic (add-drop-shadow and analyze-backdrop)

Fix add-drop-shadow.ts (Fixes 400 Error):

Open: server/image-processing/add-drop-shadow.ts.

Find: Line 83: uploadData.append('file', img.data);

Replace with: This code correctly strips the data URL prefix.

TypeScript

// Strip the data URL prefix to send only the base64 string
const base64Data = img.data.replace(/^data:image\/[a-z]+;base64,/, '');
uploadData.append('file', `data:image/png;base64,${base64Data}`);
Implement Missing analyze-backdrop API:

Open: server/image-processing/analyze-images.ts.

Add this new function to the file:

TypeScript

// New function to analyze backdrop
export async function analyzeBackdrop(req: AnalyzeImagesRequest) {
  const { files, requirements } = req;

  // Use the existing analyzeImages function with a specific prompt
  const result = await analyzeImages({
    files,
    requirements: "Analyze this image. Find the main 'floor' surface, excluding vertical 'wall' surfaces. Return a JSON object with one key, 'floorY', representing the vertical center of this floor as a fraction from 0.0 (top) to 1.0 (bottom). Example: { \"floorY\": 0.85 }."
  });

  // Try to parse the AI's response
  let floorY = 0.75; // Default fallback
  if (result.analyses && result.analyses.length > 0) {
    try {
      const analysis = result.analyses[0].analysis;
      // The prompt asks for JSON, but Gemini might return it in a text block
      const jsonMatch = analysis.description.match(/\{.*\}/s);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        if (parsed.floorY && typeof parsed.floorY === 'number') {
          floorY = parsed.floorY;
        }
      }
    } catch (e) {
      console.error("Failed to parse floorY from Gemini:", e);
      // Fallback to 0.75
    }
  }

  return { success: true, floorY };
}
Open: server/routes.ts.

Add the new route:

TypeScript

app.post("/api/analyze-backdrop", upload.single('image'), async (req: Request, res: Response) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: "No image file provided" });
    }
    const fileData = req.file.buffer.toString('base64');
    const { analyzeBackdrop } = await import("./image-processing/analyze-images");

    const result = await analyzeBackdrop({
      files: [{ data: fileData, name: req.file.originalname, type: req.file.mimetype }],
    });

    res.json(result);
  } catch (error) {
    console.error("Error in analyze-backdrop:", error);
    res.status(500).json({ error: error instanceof Error ? error.message : "Backdrop analysis failed" });
  }
});
Phase 3: Fix Client-Side API & Components

Update src/lib/api-client.ts:

Remove: Delete the entire removeBackgrounds (plural) function.

Add: Add the new analyzeBackdrop function:

TypeScript

analyzeBackdrop: (formData: FormData) => apiUpload<{ floorY: number }>('/api/analyze-backdrop', formData),
Fix addDropShadow: Update it to match the server (it still takes JSON):

TypeScript

addDropShadow: (data: any) => apiRequest('/api/add-drop-shadow', {
  method: 'POST',
  body: JSON.stringify(data),
}),
Fix BackgroundRemovalStep.tsx (The removeBackgrounds loop):

Open: src/components/BackgroundRemovalStep.tsx.

Replace the entire handleRemoveBackgrounds function with this new one that processes files one-by-one:

TypeScript

const handleRemoveBackgrounds = async () => {
  setIsProcessingLocal(true);
  setProgress(0);
  setFailedImages([]);
  setCurrentProcessingStep('Initializing...');

  const allResults: ProcessedImage[] = [];
  const failed: { name: string; error: string; file: File }[] = [];

  for (let i = 0; i < files.length; i++) {
    const file = files[i];
    const imageProgress = ((i / files.length) * 100);

    setCurrentProcessingStep(`Processing image ${i + 1} of ${files.length}: ${file.name}...`);
    setProgress(imageProgress);

    try {
      // Call the singular, fixed API
      const result = await api.removeBackground(file, (file as any).originalSize || file.size);

      if (result?.images && result.images.length > 0) {
        const img = result.images[0];
        allResults.push({
          name: img.name,
          originalData: URL.createObjectURL(file), // Create blob URL for preview
          backgroundRemovedData: img.transparentData,
          size: img.size || 0,
          originalSize: (file as any).originalSize || file.size
        });
      } else {
        throw new Error('No results returned from API');
      }
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : "Unknown error";
      failed.push({
        name: file.name,
        error: errorMessage,
        file: file
      });
      toast({
        title: "Processing Failed",
        description: `${file.name} failed. You can retry.`,
        variant: "destructive",
      });
    }
  }

  setProgress(100);
  setCurrentProcessingStep('Complete!');
  setProcessedImages(allResults);
  setFailedImages(failed as any); // Update failed state

  if (failed.length === 0) {
    onProcessingComplete(allResults);
  }
};
Fix retryFailedImage: This function was also using the old JSON API. Replace it to use the new FormData API.

TypeScript

const retryFailedImage = async (failedImage: { name: string; error: string; file: File }) => {
  setCurrentProcessingStep(`Retrying ${failedImage.name}...`);

  try {
    const result = await api.removeBackground(failedImage.file, (failedImage.file as any).originalSize || failedImage.file.size);

    if (result?.images && result.images.length > 0) {
      const img = result.images[0];
      const newProcessed: ProcessedImage = {
        name: img.name,
        originalData: URL.createObjectURL(failedImage.file),
        backgroundRemovedData: img.transparentData,
        size: img.size || 0,
        originalSize: (failedImage.file as any).originalSize || failedImage.file.size
      };

      setProcessedImages(prev => [...prev, newProcessed]);
      setFailedImages(prev => prev.filter(f => f.name !== failedImage.name));

      toast({
        title: "Success!",
        description: `${failedImage.name} processed successfully`,
      });
    } else {
      throw new Error('Retry failed');
    }
  } catch (error) {
    toast({
      title: "Retry Failed",
      description: `${failedImage.name} still failed after retry`,
      variant: "destructive",
    });
  }
  setCurrentProcessingStep('Retry complete.');
};
Update failedImages state:

TypeScript

const [failedImages, setFailedImages] = useState<{name: string, error: string, file: File}[]>([]);
Update retryFailedImage call in JSX (line 309):

JavaScript

onClick={() => retryFailedImage(image)}
Fix onContinue Button (line 330): This must pass processedImages to the parent.

JavaScript

onClick={() => onContinue(processedImages)}
Fix BackdropPositioning.tsx (Tiling & Floating Bug):

Open: src/components/BackdropPositioning.tsx

Find: The getPreviewStyles function.

Fix backdropStyles: Add backgroundRepeat: 'no-repeat' and fix backgroundSize:

TypeScript

backdropStyles: {
  backgroundImage: `url(${backdrop})`,
  backgroundRepeat: 'no-repeat', // Add this
  backgroundSize: 'cover', // Change from 'auto 100%'
  backgroundPosition: 'center', // Simplify
  aspectRatio: `${finalAspectRatio}`,
},
Fix useEffect Preview Bug: The getPreviewCutout function is buggy. Replace it with this correct logic:

TypeScript

useEffect(() => {
  const getPreviewCutout = async () => {
    if (!allSubjects || allSubjects.length === 0) {
      setPreviewError("No subjects found to preview.");
      setIsPreviewLoading(false);
      return;
    }

    const firstSubject = allSubjects[0];
    setPreviewError(null);
    setIsPreviewLoading(true);

    try {
      let cutoutData: string;

      // --- THIS IS THE BUG FIX ---
      if (isPreCut) {
        // Subject is a File, we need to read it
        console.log("Loading pre-cut preview...");
        cutoutData = await fileToDataUrl(firstSubject as File);
      } else {
        // Subject is an object, we just get the data
        console.log("Loading processed cutout preview...");
        cutoutData = (firstSubject as ProcessedSubject).backgroundRemovedData;
      }
      // --- END BUG FIX ---

      if (!cutoutData) throw new Error("Cutout data is empty.");

      setPreviewCutout(cutoutData);
      const dims = await getImageDimensions(cutoutData);
      setSubjectDimensions({ w: dims.width, h: dims.height });
    } catch (error) {
      console.error("Preview Generation Error:", error);
      setPreviewError("Could not load preview cutout. Please go back and retry.");
    } finally {
      setIsPreviewLoading(false);
    }
  };
  getPreviewCutout();
}, [allSubjects, isPreCut]);
Fix handleLibrarySelect: This function must also call the api.analyzeBackdrop. Replace the existing function with:

TypeScript

const handleLibrarySelect = async (backdrop: any, imageUrl: string) => {
  setIsBackdropAnalyzing(true);
  setAiFloorY(null);
  setBackdrop(imageUrl); // Set preview from blob URL

  try {
    // Convert the blob URL back to a File to send to analysis
    const response = await fetch(imageUrl);
    const blob = await response.blob();
    const file = new File([blob], backdrop.name, { type: blob.type });
    setBackdropFile(file);

    const formData = new FormData();
    formData.append('image', file);
    const { floorY } = await api.analyzeBackdrop(formData);

    setAiFloorY(floorY);
    setPlacement(prev => ({ ...prev, y: floorY }));
    toast({
      title: "Backdrop Selected",
      description: `Using "${backdrop.name}" and snapped floor to ${Math.round(floorY * 100)}%`,
    });
  } catch (error) {
    console.error('Error selecting/analyzing library backdrop:', error);
    toast({
      title: "Error",
      description: "Failed to analyze backdrop. Defaulting to 75%.",
      variant: "destructive"
    });
    setAiFloorY(0.75);
    setPlacement(prev => ({ ...prev, y: 0.75 }));
  } finally {
    setIsBackdropAnalyzing(false);
  }
};
Fix handleBackdropUpload: This also needs to call the AI analyzer. Replace the existing function with:

TypeScript

const handleBackdropUpload = async (event: React.ChangeEvent<HTMLInputElement>) => {
  const file = event.target.files?.[0];
  if (file) {
    setBackdropFile(file);
    setIsBackdropAnalyzing(true);
    setAiFloorY(null);
    setBackdrop(""); // Clear old backdrop

    try {
      const dataUrl = await fileToDataUrl(file);
      setBackdrop(dataUrl);

      // Call AI Floor Detection
      const formData = new FormData();
      formData.append('image', file);
      const { floorY } = await api.analyzeBackdrop(formData);

      setAiFloorY(floorY);
      setPlacement(prev => ({ ...prev, y: floorY }));
      toast({
        title: "AI Floor Detection",
        description: `Floor snapped to ${Math.round(floorY * 100)}%`,
      });

    } catch (error) {
      console.error('Error analyzing backdrop:', error);
      toast({
        title: "AI Analysis Failed",
        description: "Defaulting to 75%. You can position it manually.",
        variant: "destructive"
      });
      setAiFloorY(0.75);
      setPlacement(prev => ({ ...prev, y: 0.75 }));
    } finally {
      setIsBackdropAnalyzing(false);
    }
  }
};
Phase 4: Implement Final Compositing Fix (Reflection Bug)

Open: src/lib/canvas-utils.ts

Replace the entire compositeLayers function with this new version. This implements the final "Subject-Centric Cropping" and fixes the reflection bug .

TypeScript

export const compositeLayers = async (
  backdropUrl: string,
  subjectWithShadowUrl: string,
  cleanSubjectUrl: string,
  placement: SubjectPlacement, // Contains the X/Y *floor* placement
  outputCanvasSize: { width: number; height: number },
  padding: number // Master padding (e.g., 20)
): Promise<string> => {

  console.log('ðŸŽ¨ COMPOSITING: Starting Subject-Centric composite');

  try {
    const [backdrop, subjectWithShadow, cleanSubject] = await Promise.all([
      loadImage(backdropUrl, 'backdrop'),
      loadImage(subjectWithShadowUrl, 'subject with shadow'),
      loadImage(cleanSubjectUrl, 'clean subject')
    ]);

    const canvas = document.createElement('canvas');
    canvas.width = outputCanvasSize.width;
    canvas.height = outputCanvasSize.height;
    const ctx = canvas.getContext('2d');

    if (!ctx) {
      throw new Error('Failed to get canvas context');
    }

    console.log('Canvas created:', `${canvas.width}x${canvas.height}`);

    // --- 1. Draw Backdrop (Cropped/Zoomed) ---
    console.log('Drawing backdrop with "zoom" effect...');
    const canvasAspect = canvas.width / canvas.height;
    const backdropAspect = backdrop.width / backdrop.height;

    let drawW, drawH, drawX, drawY;

    // This logic mimics CSS "background-size: cover"
    if (backdropAspect > canvasAspect) { // Backdrop is wider than canvas
      drawH = canvas.height;
      drawW = backdrop.width * (canvas.height / backdrop.height);
      drawX = -(drawW - canvas.width) * 0.5; // Center horizontally
      drawY = 0;
    } else { // Backdrop is taller than canvas
      drawW = canvas.width;
      drawH = backdrop.height * (canvas.width / backdrop.width);
      drawX = 0;
      // Align the backdrop's "floor" (placement.y) with the canvas's "floor"
      const backdropFloorPx = backdrop.height * placement.y;
      const canvasFloorPx = canvas.height * placement.y;
      drawY = canvasFloorPx - (backdropFloorPx * (drawW / backdrop.width));
    }

    ctx.drawImage(backdrop, drawX, drawY, drawW, drawH);

    // --- 2. Calculate Subject Position (based on padding) ---
    const paddingPercent = padding / 100;
    const subjectAspectRatio = subjectWithShadow.naturalWidth / subjectWithShadow.naturalHeight;

    const innerBoxW = canvas.width * (1 - paddingPercent * 2);
    const innerBoxH = canvas.height * (1 - paddingPercent * 2);

    let scaledWidth = innerBoxW;
    let scaledHeight = scaledWidth / subjectAspectRatio;

    if (scaledHeight > innerBoxH) {
      scaledHeight = innerBoxH;
      scaledWidth = scaledHeight * subjectAspectRatio;
    }

    // Position subject centered on X, and aligned to Y (floor)
    const dx = (canvas.width - scaledWidth) / 2;
    // Adjust dy to align bottom of subject (minus padding) to the floor
    const bottomPadding = canvas.height * paddingPercent;
    const subjectFloorY = canvas.height * placement.y;
    const dy = subjectFloorY - scaledHeight - (bottomPadding * 0.5); // Position above floor

    console.log('Subject positioning:', {
      size: `${scaledWidth}x${scaledHeight}`,
      position: `${Math.round(dx)}, ${Math.round(dy)}`
    });

    // --- 3. Generate and Draw Reflection (THE FIX) ---
    console.log('ðŸªž Generating canvas-based reflection...');

    const reflectionHeight = scaledHeight * 0.6; // 60% height
    ctx.save();
    // Position *exactly* at the subject's floor line
    ctx.translate(dx, subjectFloorY);
    ctx.scale(1, -1); // Flip vertically

    // Draw the *clean* subject (flipped)
    ctx.drawImage(cleanSubject, 0, 0, scaledWidth, reflectionHeight);

    // Apply fade gradient
    const gradient = ctx.createLinearGradient(0, 0, 0, reflectionHeight);
    gradient.addColorStop(0, 'rgba(0, 0, 0, 0.4)'); // Start at 40% opacity
    gradient.addColorStop(0.6, 'rgba(0, 0, 0, 0.1)');
    gradient.addColorStop(1, 'rgba(0, 0, 0, 0)');

    ctx.globalCompositeOperation = 'destination-in';
    ctx.fillStyle = gradient;
    ctx.fillRect(0, 0, scaledWidth, reflectionHeight);
    ctx.filter = 'blur(2px)';
    ctx.globalCompositeOperation = 'source-over';

    // We must draw onto a temp canvas to apply filter, then draw back
    const tempReflectCanvas = document.createElement('canvas');
    tempReflectCanvas.width = scaledWidth;
    tempReflectCanvas.height = reflectionHeight;
    const tempCtx = tempReflectCanvas.getContext('2d');
    if (tempCtx) {
      tempCtx.drawImage(canvas, 0, 0, scaledWidth, reflectionHeight, 0, 0, scaledWidth, reflectionHeight);
      ctx.clearRect(0, 0, scaledWidth, reflectionHeight);
      ctx.drawImage(tempReflectCanvas, 0, 0);
    }

    ctx.restore(); // Restore context (removes flip, blur, etc.)

    // --- 4. Draw Subject (with shadow) ---
    console.log('Drawing subject with shadow on top...');
    ctx.drawImage(subjectWithShadow, dx, dy, scaledWidth, scaledHeight);

    const finalDataUrl = canvas.toDataURL('image/png');
    console.log('Compositing complete.');

    return finalDataUrl;

  } catch (error) {
    console.error('Error during compositing:', error);
    throw error;
  }
};
Update src/components/BatchProcessingStep.tsx:

Find: const finalImage = await compositeLayers(...).

Add the missing masterRules.padding argument:

TypeScript

const finalImage = await compositeLayers(
  backdrop,
  subjectWithShadow,
  cleanCutoutData,
  masterRules.placement,
  outputCanvasSize,
  masterRules.padding // Add this
);