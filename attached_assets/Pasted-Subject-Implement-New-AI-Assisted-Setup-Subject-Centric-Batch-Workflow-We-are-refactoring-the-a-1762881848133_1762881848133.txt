Subject: Implement New "AI-Assisted Setup, Subject-Centric Batch" Workflow

We are refactoring the app's core image processing workflow to improve realism and stability. The new architecture is called the "AI-Assisted Setup, Subject-Centric Batch" model.

The goal is to replace the current multi-step batch process with a resilient, one-file-at-a-time loop. This new loop will use a "Subject-Centric Cropping" logic to ensure image quality is preserved, and it will replace all client-side canvas compositing with a new Adobe Photoshop API endpoint.

Please perform the following tasks:

Task 1: Remove Redundant Step
In src/components/CommercialEditingWorkflow.tsx, remove the ImageRotationStep from the WorkflowStep type and all logic.

The correctImageOrientation utility already handles this at the upload stage, so the manual step is redundant.

Remove the ShadowGenerationStep from the WorkflowStep type and all logic. This is being replaced by the new Adobe API.

Task 2: Create New AI Server Endpoint for Backdrop Analysis
Create a new function in server/image-processing/analyze-images.ts (or a new file) called analyzeBackdrop.

This function should use the Gemini Vision API.

Master Prompt: It must analyze an uploaded backdrop image (like 16FEB5F5-5D42-4956-B11F-176089E5B232_1_201_a.jpg-e2bdbf8d-dbee-4254-b375-bf7ac2aea2e0) and identify the "floor" or "surface" line.

It must return a JSON object with a single y coordinate (as a fraction from 0.0 to 1.0) representing the center of this floor surface. Example: { "floorY": 0.8 }.

Add a new route, /api/analyze-backdrop, in server/routes.ts that uses multer to accept a single image and calls this new function.

Task 3: Update BackdropPositioning.tsx to become the "Master Setup"
Modify src/components/BackdropPositioning.tsx to implement the "AI-Assisted Setup."

On Load:

Automatically call api.removeBackground for the first image (cutoutImages[0]) to get a transparent preview. Show a loading state in the preview window while this is happening.

Once the user uploads a backdrop (using handleBackdropUpload), immediately call the new /api/analyze-backdrop endpoint.

AI "Snap":

When both the cutout and backdrop analysis are complete, automatically "snap" the cutout's placement state to x: 0.5 and y: data.floorY.

The user must be able to drag the cutout to override this AI-detected position.

New UI Controls:

Remove the "Product Size" Slider.

Add a new Slider for "Padding" (min 5%, max 50%, step 1%, default 20%).

Add ToggleGroup buttons for "Aspect Ratio" (options: '1:1', '4:3', '3:4', 'Original').

On Continue:

The onPositioningComplete function must now pass all the "Master Rules" to the next step:

The full-resolution backdrop data URL.

The final masterPlacement (either the AI's or the user's override).

The masterPadding value.

The masterAspectRatio string.

Task 4: Create the "Waiting Room" Component
Create a new component src/components/BatchProcessingStep.tsx. This component will replace the compositing Loader2 in CommercialEditingWorkflow.tsx.

Props: It must accept files (the full list of 20 transparent cutouts), backdrop, masterPlacement, masterPadding, and masterAspectRatio.

UI: It must show a persistent progress bar (e.g., "Processing 2 of 20...") and a list of completed/failed files.

Logic (The Loop): It must iterate through the files array one by one.

Inside the loop, for each file, it must:

Read Dimensions: Get the width and height of the current transparent cutout.

Calculate Crop: Write a client-side function to calculate the final outputCanvasSize (width/height) based on the cutout's dimensions, the masterPadding, and the masterAspectRatio. This logic must preserve the cutout's quality (no upscaling).

Call Adobe API: await api.generatePhotoshopComposite(...) (see Task 5).

Update Progress: Update the progress bar and UI.

Handle Failure: If the API call fails, add the file to a "failed" list and continue to the next image.

On Complete: When the loop finishes, it must call onProcessingComplete with the list of final processed images.

Task 5: Create the Adobe API Endpoint
Create a new file: server/image-processing/generate-photoshop-composite.ts.

Create a new route in server/routes.ts: /api/generate-photoshop-composite.

This route must use multer to accept image (the cutout), backdrop (the backdrop file), and text fields for the JSON instructions (outputCanvasSize, masterPlacement, etc.).

This function's sole responsibility is to call the Adobe Photoshop API (or Firefly Services API).

API Instructions: You must construct the actionJSON or API payload for Adobe to perform the following operations in order:

Create a new canvas with the exact outputCanvasSize (e.g., 360x360).

Add the backdrop image as the base layer. It must be scaled and cropped (not stretched) to fill the canvas, with its "floor" aligned to the masterPlacement.y coordinate.

Add the image (cutout) as a new layer on top, placed according to the masterPlacement and masterPadding rules.

Generate a realistic ground shadow for the cutout layer, using the "master prompt" (elevated, front-on light, soft blur).

Generate a realistic reflection for the cutout layer.

Return the final, merged PNG.

This endpoint replaces all logic from the old src/lib/canvas-utils.ts and server/image-processing/add-drop-shadow.ts.